---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.7
  kernelspec:
    display_name: R
    name: ir
output:
  html_document:
    df_print: paged
---


# Machine Learning Final Project
*Authors: David Costa, Lucas Gaspar*


## Project Description

The goal of this project is to apply multiple machine/statistical learning techniques we've learned over the course of the semester in MATH 4050 to a fictional dataset of 8,000 observations with 31 features. We intend to use unsupervised learning (Hierarchical clustering) to conduct some preliminary examination and help guide the decision of which features to use as response variables (1 categorical and 1 numerical). We will then use best practices to develop Linear/Logistic regression, Decision Tree, Random Forest, and Support Vector Machine models. Along the way we will use various tuning methods, validation techiniques, and dimensional reduction techniques to ensure that our models are well fit, and robust.

The data used in the project is a fictional dataset containing 31 features about a given household. It contains 16 categorical and 15 numerical variables:

| Feature     | Description                                                                 |
|-------------|-----------------------------------------------------------------------------|
| **urbrur**  | Whether the household is located in urban or rural location                 |
| **hhsize**  | Household size (number of members)                                          |
| **statocc** | Whether the household rents, owns, or has free occupancy                    |
| **rooms**   | Number of rooms in the household                                             |
| **bedrooms**| Number of bedrooms in the household                                          |
| **floor**   | Floor number where the household is located (if applicable)                 |
| **walls**   | Type of walls in the household                                               |
| **roof**    | Type of roof in the household                                                |
| **electricity** | Whether the household has electricity                                    |
| **cook_fuel** | Type of cooking fuel used in the household                                |
| **phone**   | Whether the household has a phone                                            |
| **cell**    | Whether the household has a mobile phone                                     |
| **car**     | Whether the household has a car                                              |
| **bicycle** | Whether the household has a bicycle                                          |
| **motorcycle** | Whether the household has a motorcycle                                    |
| **refrigerator** | Whether the household has a refrigerator                                |
| **tv**      | Whether the household has a television                                       |
| **radio**   | Whether the household has a radio                                            |
| **bank**    | Whether the household has a bank account                                     |
| **exp_01**  | Annual spending on Food and non-alcoholic beverages                          |
| **exp_02**  | Annual spending on Alcoholic beverages, tobacco and narcotics                |
| **exp_03**  | Annual spending on Clothing and footwear                                     |
| **exp_04**  | Annual spending on Housing, water, electricity, gas and other fuels          |
| **exp_05**  | Annual spending on Furnishing, household equipment and routine maintenance   |
| **exp_06**  | Annual spending on Health                                                    |
| **exp_07**  | Annual spending on Transport                                                 |
| **exp_08**  | Annual spending on Communication                                             |
| **exp_09**  | Annual spending on Recreation and culture                                    |
| **exp_10**  | Annual spending on Education                                                 |
| **exp_11**  | Annual spending on Catering and accommodation services                       |
| **exp_12**  | Annual spending on Miscellaneous goods and services                         |


```{r}
df <- read.csv("https://raw.githubusercontent.com/costad3atwit/Machine_Learning_Final/refs/heads/main/projectData.csv")
```

```{r}
#install.packages("gower")
library(gower)
#install.packages("StatMatch")
library(StatMatch)
```


```{r}
#Rename confusing variables

df <- df %>% rename(
  spend_food = exp_01,
  spend_alcohol = exp_02,
  spend_clothes = exp_03,
  spend_housing = exp_04,
  spend_furnishing = exp_05,
  spend_health = exp_06,
  spend_transport = exp_07,
  spend_communication = exp_08,
  spend_recreation = exp_09,
  spend_education = exp_10,
  spend_catering = exp_11,
  spend_misc = exp_12
)

df$X <- NULL
```


```{r}
df$tv <- as.factor(df$tv)
df$urbrur <- as.factor(df$urbrur)
df$statocc <- as.factor(df$statocc)
df$floor <- as.factor(df$floor)
df$walls <- as.factor(df$walls)
df$roof <- as.factor(df$roof)
df$electricity <- as.factor(df$electricity)
df$cook_fuel <- as.factor(df$cook_fuel)
df$phone <- as.factor(df$phone)
df$cell <- as.factor(df$cell)
df$car <- as.factor(df$car)
df$bicycle <- as.factor(df$bicycle)
df$motorcycle <- as.factor(df$motorcycle)
df$refrigerator <- as.factor(df$refrigerator)
df$radio <- as.factor(df$radio)
df$bank <- as.factor(df$bank)

str(df)
```

```{r}
head(df)
```
### FAMD Testing

```{r}
# Load required packages
library(FactoMineR)
library(factoextra)

# Ensure row names are unique before any processing
#rownames(df) <- paste0("row_", 1:nrow(df))

df_famd <- df

# Perform the FAMD analysis with error handling
res.famd <- FAMD(df_famd, graph = FALSE, ncp = 5)

# Scree plot should work regardless of row names
print("Generating scree plot...")
scree_plot <- fviz_screeplot(res.famd)
print(scree_plot)

# Try visualization with row names explicitly set
print("Generating individual plot...")

# Extract the individual coordinates
ind_coords <- as.data.frame(res.famd$ind$coord)

# Make sure the row names are properly set
rownames(ind_coords) <- paste0("row_", 1:nrow(ind_coords))

# Manual plotting as an alternative to fviz_famd_ind
library(ggplot2)

# Get the cos2 values for coloring
cos2 <- rowSums(res.famd$ind$cos2[,1:2])

# Create a data frame for plotting
plot_df <- data.frame(
Dim1 = ind_coords[,1],
  Dim2 = ind_coords[,2],
  cos2 = cos2
)

# Create the plot
ind_plot <- ggplot(plot_df, aes(x = Dim1, y = Dim2, color = cos2)) +
  geom_point(size = 3) +
  scale_color_gradient2(low = "#00AFBB", mid = "#E7B800", high = "#FC4E07",
                       midpoint = median(cos2)) +
  theme_minimal() +
  labs(title = "Individuals - FAMD",
       x = paste0("Dim 1 (", round(res.famd$eig[1,2], 1), "%)"),
       y = paste0("Dim 2 (", round(res.famd$eig[2,2], 1), "%)"))

print(ind_plot)

# Try the variable plot
print("Generating variable plot...")
var_plot <- fviz_famd_var(res.famd, repel = TRUE)
print(var_plot)

  
# Display the structure of your data for debugging
print("Structure of the first few rows of your data:")
print(str(head(df_famd)))
```
Scree Plot
- represents how much variance explained in how many dimensions. ~30% in 2 is not very good
- not sure how to apply this yet

Individuals
- hotter means better represented in those dimensions

Variables
- kinda shows how variables are grouped i think
- it looks like theres some patterns of what the variables are and how well one thing explains them



## Unsupervised Data Analysis: Clustering

We use cluster analysis to help pick an interesting response variable via hierarchical clustering

- Tune “cut-off height” for clusters (dissimilarity)
- To determine what we would like to predict (1 categorical and 1 numerical) and understand the data a little better.
- Use Gower distance w/ hierarchical cus mixed data (chapter 12 lab)
- Include formula for gower distance in rmd
- Explain how hierarchical clustering converges to 1 or more clusters


```{r}
gower_df = gower.dist(df)
```

```{r}
library(cluster)
```

We'll use the Partitions Around Mediods (PAM) Method of clustering to look for best clustering and subsequently the most impactful features. We'll use those features to decide what to predict.

```{r}
pam_result_2 <- pam(gower_df, k=2, diss=TRUE)
sil_2 = silhouette(pam_result_2)
pam_result_3 <- pam(gower_df, k=3, diss=TRUE)
sil_3 = silhouette(pam_result_3)
pam_result_4 <- pam(gower_df, k=4, diss=TRUE)
sil_4 = silhouette(pam_result_4)
pam_result_5 <- pam(gower_df, k=5, diss=TRUE)
sil_5 = silhouette(pam_result_5)
pam_result_6 <- pam(gower_df, k=6, diss=TRUE)
sil_6 = silhouette(pam_result_6)
pam_result_7 <- pam(gower_df, k=7, diss=TRUE)
sil_7 = silhouette(pam_result_7)
```

```{r}
par(mfrow = c(1,2))
plot(sil_2, main = "Silhouette Chart with 2 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
plot(sil_3, main = "Silhouette Chart with 3 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue","green"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
```
```{r}
par(mfrow = c(1,2))
plot(sil_4, main = "Silhouette Chart with 4 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue","green", "purple"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
plot(sil_5, main = "Silhouette Chart with 5 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue","green", "purple", "cyan"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
```

```{r}
par(mfrow = c(1,2))
plot(sil_6, main = "Silhouette Chart with 6 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue","green", "purple", "cyan", "black"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
plot(sil_7, main = "Silhouette Chart with 7 clusters",
     xlab = "", sub = "", cex = 0.9, 
     col = c("red", "blue","green", "purple", "cyan", "black", "brown"),  # Add colors for different clusters
     border = NA,             # Remove borders around individual lines
     do.n.k = TRUE,           # Show number of observations and clusters
     do.clus.stat = TRUE)     # Show cluster statistics
```


It looks like our best clustering occured with only 2 clusters because the average silhouette width was the highest among each cluster there. We'll continue using the 2 cluster model.

```{r}
df$cluster <- pam_result_2$clustering

# Create empty lists to store results
numeric_results <- list()
categorical_results <- list()

# Loop through each variable (except the cluster variable)
for(var_name in names(df)[1:31]) {

  if(is.numeric(df[[var_name]])) {
    # For numeric variables
    # Calculate mean, median, standard deviation by cluster
    stats_by_cluster <- aggregate(df[[var_name]] ~ cluster, data=df,
                                 FUN=function(x) c(mean=mean(x, na.rm=TRUE),
                                                  median=median(x, na.rm=TRUE),
                                                  sd=sd(x, na.rm=TRUE)))

    # Calculate standardized difference (Cohen's d)
    means <- c(stats_by_cluster[1,2][1], stats_by_cluster[2,2][1])
    sds <- c(stats_by_cluster[1,2][3], stats_by_cluster[2,2][3])
    pooled_sd <- sqrt((sds[1]^2 + sds[2]^2)/2)
    effect_size <- abs(means[1] - means[2])/pooled_sd

    # Perform t-test between clusters
    t_test_result <- t.test(df[[var_name]] ~ df$cluster)

    # Store results
    numeric_results[[var_name]] <- data.frame(
      variable = var_name,
      cluster1_mean = means[1],
      cluster2_mean = means[2],
      mean_difference = abs(means[1] - means[2]),
      effect_size = effect_size,
      p_value = t_test_result$p.value
    )

  } else {
    # For categorical variables
    # Create contingency table
    cont_table <- table(df$cluster, df[[var_name]])

    # Calculate proportions within each cluster
    prop_table <- prop.table(cont_table, margin=1)

    # Chi-square test
    chi_test <- chisq.test(cont_table)

    # Calculate Cramer's V (effect size for categorical variables)
    n <- sum(cont_table)
    cramers_v <- sqrt(chi_test$statistic / (n * (min(dim(cont_table)) - 1)))

    # Store results
    categorical_results[[var_name]] <- data.frame(
      variable = var_name,
      chi_square = chi_test$statistic,
      p_value = chi_test$p.value,
      cramers_v = cramers_v
    )
  }
}

# Combine results
numeric_df <- do.call(rbind, numeric_results)
categorical_df <- do.call(rbind, categorical_results)

# Sort by effect size/statistical significance
numeric_df <- numeric_df[order(-numeric_df$effect_size),]
categorical_df <- categorical_df[order(-categorical_df$cramers_v),]

# Print top 10 most differentiating variables
print("Top 10 Numeric Variables:")
print(head(numeric_df, 10))
print("Top 10 Categorical Variables:")
print(head(categorical_df, 10))
```

Based on the top ten most meaningful features derived above through clustering, we've decided to move forward with our supervised learning techniques predicting on **spend_housing** *(spending on housing AND utilities)*, **and tv** *(television)* because their effect size is high and the findings may be interesting

```{r}
#Before we move on we need to remove the cluster variable from the dataframe so we don't skew our other models
df$cluster = NULL

```

## Subsetting the Data for Regression

We'll need to set aside some test data before we work with any supervised learning techniques so that we can perform accurate validation

```{r}
sample = sample(nrow(df), nrow(df) * .75)
df.train <- df[sample, ]
df.test <- df[-sample, ]

head(df.train)

head(df.test)
```

## Linear Regression

In this section, we'll develop a linear regression model to predict housing expenditures (`spend_housing`) based on various household characteristics. Linear regression models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data.

The general form of the linear regression equation is:

$$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p + \epsilon$$

Where:
- $Y$ is the response variable (spend_housing)
- $\beta_0$ is the intercept
- $\beta_1, \beta_2, ..., \beta_p$ are the coefficients
- $X_1, X_2, ..., X_p$ are the predictor variables
- $\epsilon$ is the error term

The training process involves minimizing the Mean Squared Error (MSE), which is calculated as:

$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

Where $y_i$ is the actual value and $\hat{y}_i$ is the predicted value.

### Feature Selection using Forward Stepwise Selection

First, we'll apply forward stepwise selection to identify the most important predictors for our model:

```{r}
# Load necessary libraries for linear regression
library(leaps)
library(caret)

# Set seed for reproducibility
set.seed(123)

# Create a formula excluding the response variable
predictors <- setdiff(names(df), c("spend_housing", "cluster"))
formula_all <- as.formula(paste("spend_housing ~", paste(predictors, collapse = " + ")))

# Null model (for comparison)
null_model <- lm(spend_housing ~ 1, data = df.train)
null_mse_train <- mean(residuals(null_model)^2)
cat("Null model training MSE:", null_mse_train, "\n")

# Forward stepwise selection
forward_selection <- step(lm(spend_housing ~ 1, data = df.train), 
                         direction = "forward", 
                         scope = formula_all, 
                         trace = FALSE)

# Display the selected variables
cat("Variables selected by forward selection:\n")
print(formula(forward_selection))
```

### Fitting the Linear Model with Selected Features

Now, we'll fit the linear regression model using the features selected by forward stepwise selection:

```{r}
# Fit the linear model with selected predictors
model_forward <- lm(formula(forward_selection), data = df.train)
summary_forward <- summary(model_forward)

# Display model summary and key statistics
print(summary_forward)

# Calculate training MSE
mse_train <- mean(residuals(model_forward)^2)
cat("Training MSE:", mse_train, "\n")
cat("R-squared:", summary_forward$r.squared, "\n")
cat("Adjusted R-squared:", summary_forward$adj.r.squared, "\n")
```

### Cross-Validation for Model Evaluation

We'll use K-fold cross-validation to evaluate our model and compare it with the null model:

```{r}
# Function to calculate MSE
mse <- function(actual, predicted) {
  mean((actual - predicted)^2)
}

# Set up 10-fold cross-validation
k <- 10
set.seed(456)
folds <- createFolds(df.train$spend_housing, k = k, list = TRUE, returnTrain = FALSE)

# Function to evaluate models using k-fold CV
cv_evaluation <- function(model_formula) {
  cv_results <- data.frame(fold = integer(), train_mse = numeric(), test_mse = numeric())
  
  for (i in 1:k) {
    fold_test <- df.train[folds[[i]], ]
    fold_train <- df.train[-folds[[i]], ]
    
    model <- lm(model_formula, data = fold_train)
    
    # Predictions
    train_pred <- predict(model, fold_train)
    test_pred <- predict(model, fold_test)
    
    # Calculate MSE
    train_mse <- mse(fold_train$spend_housing, train_pred)
    test_mse <- mse(fold_test$spend_housing, test_pred)
    
    cv_results <- rbind(cv_results, data.frame(fold = i, train_mse = train_mse, test_mse = test_mse))
  }
  
  return(cv_results)
}

# Evaluate models:
# 1. Null model (just intercept)
null_model_formula <- as.formula("spend_housing ~ 1")
null_cv_results <- cv_evaluation(null_model_formula)

# 2. Forward selection model
forward_cv_results <- cv_evaluation(formula(forward_selection))

# Calculate average MSE across folds
null_avg_mse <- mean(null_cv_results$test_mse)
forward_avg_mse <- mean(forward_cv_results$test_mse)

cat("Null Model - Average CV Test MSE:", null_avg_mse, "\n")
cat("Forward Selection Model - Average CV Test MSE:", forward_avg_mse, "\n")
cat("Improvement (% reduction in MSE):", (null_avg_mse - forward_avg_mse) / null_avg_mse * 100, "%\n")
```

### Final Model Evaluation on Test Set

Now, we'll evaluate our model on the held-out test set to assess its predictive performance:

```{r}
# Make predictions on the test set
predictions <- predict(model_forward, df.test)

# Calculate test MSE
test_mse <- mse(df.test$spend_housing, predictions)
cat("Test MSE:", test_mse, "\n")

# Calculate null model test MSE for comparison
null_pred <- rep(mean(df.train$spend_housing), nrow(df.test))
null_test_mse <- mse(df.test$spend_housing, null_pred)
cat("Null Model Test MSE:", null_test_mse, "\n")

# Calculate R-squared on test data
tss <- sum((df.test$spend_housing - mean(df.test$spend_housing))^2)
rss <- sum((df.test$spend_housing - predictions)^2)
test_r_squared <- 1 - (rss/tss)
cat("Test R-squared:", test_r_squared, "\n")

# Visualize actual vs predicted values
plot(df.test$spend_housing, predictions, 
     main = "Actual vs. Predicted Housing Expenditure",
     xlab = "Actual", ylab = "Predicted",
     pch = 16, col = "blue", cex = 0.8)
abline(0, 1, col = "red", lwd = 2)
```

### Interpretation of Results

The multiple regression model reveals several significant predictors of housing expenditure. 

```{r}
# Display top 5 most significant predictors (t-value)
coef_table <- as.data.frame(summary_forward$coefficients)
coef_table$variable <- rownames(coef_table)
coef_table <- coef_table[order(-abs(coef_table$`t value`)), ]
cat("Top 5 most significant predictors of housing expenditure:\n")
print(head(coef_table[, c("variable", "Estimate", "t value", "Pr(>|t|)")], 5))

```

The multiple regression reveals insights into what drives housing expenditure:

1. **Model Performance**: The model explains approximately 93.1 of the variance in housing expenditure, which is substantially better than the null model which in this case was near 0%.

2. **Key Predictors**: The most significant predictors include spend_communication, spend_misc, rooms, wallsBrick, and spend_catering. For example, each additional dollar spent on communication is associated with an increase of $1.302 in housing expenditure, holding all other variables constant.

3. **Validation**: Cross-validation confirms the model is robust, with consistent performance across different subsets of the data.

4. **Prediction Accuracy**: The test MSE of 395058.4 indicates our model can predict housing expenditure with reasonable accuracy (Null Model Test MSE: 5440908), with a 92.105% improvement over the null model.
This improvement was calculated as $\text{Percentage Improvement}=( \frac{5004201−395058.4}{5004201})*100 ≈ 92.105%$


## Logistic Regression
- Forward Stepwise Selection:
 - Pick best subset to use for regression by comparing all models m_0, m_1, m_2…m_p using K-fold cross validation
 - 6.1 in book

Explain formula sigmoid(B0 +B1x1 B2x2…)
Train by minimizing MSE
Give MSE formula
Confirm results/pick best model using K-fold CV
Interpret results. “This data shows that we have an XX increase/decrease in [response var] when [predictor] has a unit increase”

## Decision Tree
- Only use for the categorical prediction
- Explain DT creation process briefly (Recursive Binary Splitting) (create partitions in feature space to minimize overall average partition-wise Node purity)
- Fit tree (overgrown)
- Cost complexity pruning
 - Make sure to try out different costs
- Include explanation and equation for Gini Index (Node purity)
- Plot DT

### Make Tree
```{r}
library(tree)
df.tree <- tree(df.train$tv ~ ., data = df.train)
summary(df.tree)

plot(df.tree)
text(df.tree, pretty = 0)

df.tree.pred <- predict(df.tree, df.test, type ="class")
table(Predicted = df.tree.pred, Actual = df.test$tv)
```

### Prune Tree
```{r}
#TODO NAs introduced by coercion, why... Warnings suppressed for now
cv.df.tree <- suppressWarnings(cv.tree(df.tree, FUN = prune.misclass))
plot(cv.df.tree$size, cv.df.tree$dev, type = "b")
```

```{r}
df.tree.pruned <- prune.misclass(df.tree, best = 5)
summary(df.tree.pruned)

plot(df.tree.pruned)
text(df.tree.pruned, pretty = 0)
```

## Random Forest

```{r}
library(randomForest)

df.rf <- randomForest(df.train$tv ~., data = df.train, importance = TRUE)
df.rf
```

## Support Vector Machine

```{r}

```
